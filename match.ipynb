{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_images(folder_path):\n",
    "    \"\"\"Load all images (jpg, png, etc.) from a folder.\"\"\"\n",
    "    image_paths = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')):\n",
    "            image_paths.append(os.path.join(folder_path, filename))\n",
    "    image_paths.sort()  # Ensure a consistent order\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        img = cv2.imread(path)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "        else:\n",
    "            print(f\"Warning: Could not load {path}\")\n",
    "    return images\n",
    "\n",
    "def detect_features(images, method=\"ORB\"):\n",
    "    \"\"\"\n",
    "    Detect keypoints and compute descriptors for each image using either ORB or SIFT.\n",
    "    \n",
    "    Args:\n",
    "        images (list): List of images.\n",
    "        method (str): 'ORB' or 'SIFT'\n",
    "        \n",
    "    Returns:\n",
    "        keypoints_list: List of lists of keypoints for each image.\n",
    "        descriptors_list: List of descriptor arrays for each image.\n",
    "    \"\"\"\n",
    "    method = method.upper()\n",
    "    if method == \"ORB\":\n",
    "        detector = cv2.ORB_create(nfeatures=2000)\n",
    "    elif method == \"SIFT\":\n",
    "        detector = cv2.SIFT_create()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported method. Use 'ORB' or 'SIFT'.\")\n",
    "    \n",
    "    keypoints_list = []\n",
    "    descriptors_list = []\n",
    "    for img in images:\n",
    "        kp, des = detector.detectAndCompute(img, None)\n",
    "        keypoints_list.append(kp)\n",
    "        descriptors_list.append(des)\n",
    "    return keypoints_list, descriptors_list\n",
    "\n",
    "def match_keypoints(descriptors_list, method=\"ORB\", ratio_thresh=0.75):\n",
    "    \"\"\"\n",
    "    Match keypoints between consecutive images.\n",
    "    - If method='ORB', use Hamming distance.\n",
    "    - If method='SIFT', use L2 (NORM_L2).\n",
    "    \n",
    "    Returns:\n",
    "        matches_list: List of 'good' matches between consecutive images\n",
    "                      (i.e., matches_list[i] is for images i and i+1)\n",
    "    \"\"\"\n",
    "    method = method.upper()\n",
    "    if method == \"ORB\":\n",
    "        bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "    else:  # SIFT\n",
    "        bf = cv2.BFMatcher(cv2.NORM_L2)\n",
    "    \n",
    "    matches_list = []\n",
    "    for i in range(len(descriptors_list) - 1):\n",
    "        des1 = descriptors_list[i]\n",
    "        des2 = descriptors_list[i+1]\n",
    "        if des1 is None or des2 is None:\n",
    "            print(f\"Warning: Descriptors missing for image {i} or {i+1}\")\n",
    "            matches_list.append(None)\n",
    "            continue\n",
    "        \n",
    "        raw_matches = bf.knnMatch(des1, des2, k=2)\n",
    "        good = []\n",
    "        for m, n in raw_matches:\n",
    "            if m.distance < ratio_thresh * n.distance:\n",
    "                good.append(m)\n",
    "        matches_list.append(good)\n",
    "    return matches_list\n",
    "\n",
    "\n",
    "def compute_cumulative_homographies(matches_list, keypoints_list):\n",
    "    \"\"\"\n",
    "    Compute a cumulative homography for each image relative to the first image.\n",
    "    cum_homographies[i] warps image i into the coordinate space of image 0.\n",
    "    \"\"\"\n",
    "    cum_homographies = [np.eye(3, dtype=np.float32)]  # Identity for first image\n",
    "    for i, matches in enumerate(matches_list):\n",
    "        if matches is None or len(matches) < 4:\n",
    "            # If homography can't be computed, repeat the previous one\n",
    "            cum_homographies.append(cum_homographies[-1])\n",
    "            continue\n",
    "        kp1 = keypoints_list[i]\n",
    "        kp2 = keypoints_list[i+1]\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        H, _ = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)\n",
    "        # Accumulate transform relative to image 0\n",
    "        if H is not None:\n",
    "            cum_homographies.append(cum_homographies[-1] @ H)\n",
    "        else:\n",
    "            cum_homographies.append(cum_homographies[-1])\n",
    "    return cum_homographies\n",
    "\n",
    "def stitch_images_basic(images, method=\"ORB\", ratio_thresh=0.75):\n",
    "    \"\"\"\n",
    "    Stitch all images into one panoramic image by transforming each image into\n",
    "    the coordinate space of the first image (no blending).\n",
    "    \"\"\"\n",
    "    keypoints_list, descriptors_list = detect_features(images, method=method)\n",
    "    matches_list = match_keypoints(descriptors_list, method=method, ratio_thresh=ratio_thresh)\n",
    "\n",
    "    # Compute a cumulative homography for each image index\n",
    "    cum_homographies = compute_cumulative_homographies(matches_list, keypoints_list)\n",
    "\n",
    "    # Determine the canvas size by transforming each image's corners\n",
    "    corners = []\n",
    "    for i, img in enumerate(images):\n",
    "        h, w = img.shape[:2]\n",
    "        c = np.array([[0, 0], [w, 0], [w, h], [0, h]], dtype=np.float32).reshape(-1, 1, 2)\n",
    "        warped_c = cv2.perspectiveTransform(c, cum_homographies[i])\n",
    "        corners.append(warped_c)\n",
    "    all_corners = np.vstack(corners)\n",
    "    [xmin, ymin] = np.int32(all_corners.min(axis=0).ravel())\n",
    "    [xmax, ymax] = np.int32(all_corners.max(axis=0).ravel())\n",
    "\n",
    "    # Shift matrix to avoid negative coordinates\n",
    "    shift = np.array([[1, 0, -xmin],\n",
    "                      [0, 1, -ymin],\n",
    "                      [0, 0, 1]], dtype=np.float32)\n",
    "    width, height = xmax - xmin, ymax - ymin\n",
    "    panorama = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Warp each image and place it onto the final panorama\n",
    "    for i, img in enumerate(images):\n",
    "        warp_mat = shift @ cum_homographies[i]\n",
    "        warped = cv2.warpPerspective(img, warp_mat, (width, height))\n",
    "        # Overwrite empty areas\n",
    "        mask = (warped.sum(axis=2) > 0)\n",
    "        panorama[mask] = warped[mask]\n",
    "\n",
    "    # Crop away any black edges\n",
    "    gray_pano = cv2.cvtColor(panorama, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray_pano, 1, 255, cv2.THRESH_BINARY)\n",
    "    coords = cv2.findNonZero(thresh)\n",
    "    if coords is not None:\n",
    "        x, y, w, h = cv2.boundingRect(coords)\n",
    "        panorama = panorama[y:y+h, x:x+w]\n",
    "\n",
    "    return panorama\n",
    "\n",
    "\n",
    "def feather_blend(base, warped, blend_width=30):\n",
    "    \"\"\"\n",
    "    Feather blend the overlapping region between base and warped images.\n",
    "    Assumes base and warped have the same height and partially overlapping width.\n",
    "    \"\"\"\n",
    "    h_base, w_base = base.shape[:2]\n",
    "    h_warp, w_warp = warped.shape[:2]\n",
    "    out_w = max(w_base, w_warp)\n",
    "    out_h = max(h_base, h_warp)\n",
    "    blended = np.zeros((out_h, out_w, 3), dtype=np.uint8)\n",
    "    blended[:h_base, :w_base] = base\n",
    "    overlap_x_start = 0\n",
    "    overlap_x_end = min(w_base, w_warp)\n",
    "    for x in range(overlap_x_start, overlap_x_end):\n",
    "        dist_to_base_edge = w_base - x\n",
    "        if x >= w_base:\n",
    "            blended[:h_warp, x] = warped[:h_warp, x]\n",
    "        elif x >= w_warp:\n",
    "            continue\n",
    "        else:\n",
    "            alpha = 1.0\n",
    "            if dist_to_base_edge < blend_width:\n",
    "                alpha = dist_to_base_edge / float(blend_width)\n",
    "            for y in range(0, min(h_base, h_warp)):\n",
    "                px_base = base[y, x]\n",
    "                px_warp = warped[y, x]\n",
    "                blended[y, x] = alpha * px_base + (1 - alpha) * px_warp\n",
    "    if w_warp > w_base:\n",
    "        blended[:h_warp, w_base:w_warp] = warped[:h_warp, w_base:w_warp]\n",
    "    return blended\n",
    "\n",
    "def stitch_images_feathered(images, method=\"ORB\", ratio_thresh=0.75, blend_width=30):\n",
    "    \"\"\"\n",
    "    Stitch images using keypoint matching (ORB or SIFT) and homography,\n",
    "    then apply a feather blend in the overlap region, and finally crop black areas.\n",
    "    \"\"\"\n",
    "    keypoints_list, descriptors_list = detect_features(images, method=method)\n",
    "    matches_list = match_keypoints(descriptors_list, method=method, ratio_thresh=ratio_thresh)\n",
    "    homographies = compute_homographies(matches_list, keypoints_list)\n",
    "    panorama = images[0]\n",
    "    for i in range(1, len(images)):\n",
    "        H = homographies[i - 1]\n",
    "        if H is None:\n",
    "            print(f\"Skipping image {i}, homography is None.\")\n",
    "            continue\n",
    "        h_pano, w_pano = panorama.shape[:2]\n",
    "        h2, w2 = images[i].shape[:2]\n",
    "        warped_img = cv2.warpPerspective(images[i], H, (w_pano + w2, h_pano))\n",
    "        panorama = feather_blend(panorama, warped_img, blend_width=blend_width)\n",
    "    gray_panorama = cv2.cvtColor(panorama, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray_panorama, 1, 255, cv2.THRESH_BINARY)\n",
    "    coords = cv2.findNonZero(thresh)\n",
    "    if coords is not None:\n",
    "        x, y, w, h = cv2.boundingRect(coords)\n",
    "        panorama = panorama[y:y+h, x:x+w]\n",
    "    return panorama\n",
    "\n",
    "\n",
    "def plot_and_print_keypoints(images, keypoints_list, method=\"ORB\", output_folder=\".\"):\n",
    "    \"\"\"\n",
    "    For each input image, draw the detected keypoints, save the plotted image,\n",
    "    and print the coordinates (first 10 keypoints for brevity).\n",
    "    \n",
    "    Args:\n",
    "        images (list): List of images.\n",
    "        keypoints_list (list): List of keypoints for each image.\n",
    "        method (str): 'ORB' or 'SIFT'.\n",
    "        output_folder (str): Folder to save keypoint images.\n",
    "    \"\"\"\n",
    "    method = method.upper()\n",
    "    for idx, (img, kp) in enumerate(zip(images, keypoints_list)):\n",
    "        img_kp = cv2.drawKeypoints(img, kp, None, flags=cv2.DrawMatchesFlags_DRAW_RICH_KEYPOINTS)\n",
    "        output_name = os.path.join(output_folder, f\"keypoints_{method}_{idx}.jpg\")\n",
    "        cv2.imwrite(output_name, img_kp)\n",
    "        print(f\"Saved keypoints image: {output_name}\")\n",
    "        print(f\"Image {idx} ({method}) - Number of keypoints: {len(kp)}\")\n",
    "        for i, point in enumerate(kp[:10]):\n",
    "            print(f\"  Keypoint {i}: {point.pt}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "def ensure_output_folder(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "def main():\n",
    "    input_folder = \"unstitchedImages/\"\n",
    "    output_folder = \"output/\"\n",
    "    ensure_output_folder(output_folder)\n",
    "    \n",
    "    images = load_images(input_folder)\n",
    "    if len(images) < 2:\n",
    "        print(\"Not enough images to stitch.\")\n",
    "        return\n",
    "    \n",
    "    # Process and display keypoints for SIFT\n",
    "    print(\"\\nProcessing SIFT keypoints:\")\n",
    "    keypoints_sift, _ = detect_features(images, method=\"SIFT\")\n",
    "    plot_and_print_keypoints(images, keypoints_sift, method=\"SIFT\", output_folder=output_folder)\n",
    "    \n",
    "    # 1) SIFT (no blending)\n",
    "    print(\"\\nStitching with SIFT (no blending)...\")\n",
    "    panorama_sift_basic = stitch_images_basic(images, method=\"SIFT\", ratio_thresh=0.75)\n",
    "    cv2.imwrite(os.path.join(output_folder, \"final_panorama_sift.jpg\"), panorama_sift_basic)\n",
    "    print(\"Saved: final_panorama_sift.jpg\")\n",
    "    \n",
    "    # 2) SIFT + Feather Blending\n",
    "    print(\"\\nStitching with SIFT + Feather Blending...\")\n",
    "    panorama_sift_feather = stitch_images_feathered(images, method=\"SIFT\", ratio_thresh=0.75, blend_width=50)\n",
    "    cv2.imwrite(os.path.join(output_folder, \"final_panorama_sift_feather.jpg\"), panorama_sift_feather)\n",
    "    print(\"Saved: final_panorama_sift_feather.jpg\")\n",
    "    \n",
    "    # Process and display keypoints for ORB\n",
    "    print(\"\\nProcessing ORB keypoints:\")\n",
    "    keypoints_orb, _ = detect_features(images, method=\"ORB\")\n",
    "    plot_and_print_keypoints(images, keypoints_orb, method=\"ORB\", output_folder=output_folder)\n",
    "    \n",
    "    # 3) ORB (no blending)\n",
    "    print(\"\\nStitching with ORB (no blending)...\")\n",
    "    panorama_orb_basic = stitch_images_basic(images, method=\"ORB\", ratio_thresh=0.75)\n",
    "    cv2.imwrite(os.path.join(output_folder, \"final_panorama_orb.jpg\"), panorama_orb_basic)\n",
    "    print(\"Saved: final_panorama_orb.jpg\")\n",
    "    \n",
    "    # 4) ORB + Feather Blending\n",
    "    print(\"\\nStitching with ORB + Feather Blending...\")\n",
    "    panorama_orb_feather = stitch_images_feathered(images, method=\"ORB\", ratio_thresh=0.75, blend_width=50)\n",
    "    cv2.imwrite(os.path.join(output_folder, \"final_panorama_orb_feather.jpg\"), panorama_orb_feather)\n",
    "    print(\"Saved: final_panorama_orb_feather.jpg\")\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pe2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
